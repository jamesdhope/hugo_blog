---
title:  "Programmable, semantically-matched guardrails with NVIDIA/NeMo-Guardrails and watsonx.ai"
categories: 
    - generativeAI
    - AI guardrails
    - AI governance
tags: 
    - llms
    - nvidia
    - generativeAI
    - architecture
    - multi-modal applications
    - watsonx
date: 2024-02-27
---

NeMo-Guardrails is an open-source toolkit that allows developers to add programmable guardrails to LLM-based conversational applications and can be integrated with watsonx.ai models using LangChain's WatsonxLLM Integration.

#### Five types of guardrails

The framework supports five types of guardrails:

1. Input rails: applied to the input from the user; an input rail can reject the input, stopping any additional processing, or alter the input (e.g., to mask potentially sensitive data, to rephrase).

2. Dialog rails: influence how the LLM is prompted; dialog rails operate on canonical form messages (more details here) and determine if an action should be executed, if the LLM should be invoked to generate the next step or a response, if a predefined response should be used instead, etc.

3. Retrieval rails: applied to the retrieved chunks in the case of a RAG (Retrieval Augmented Generation) scenario; a retrieval rail can reject a chunk, preventing it from being used to prompt the LLM, or alter the relevant chunks (e.g., to mask potentially sensitive data).

4. Execution rails: applied to input/output of the custom actions (a.k.a. tools), that need to be called by the LLM.

5. Output rails: applied to the output generated by the LLM; an output rail can reject the output, preventing it from being returned to the user, or alter it (e.g., removing sensitive data).

![NeMo-Guardrails](nemo.png)

#### Semantic-matching guardrails

At the core of NeMo Guardrails is the Colang modeling language. Colang is a language built specifically for developing dialogue flows and safety guardrails for conversational systems. Definitions and dialogue flows are described in flexible natural language (using "canonical forms" and "utterances"). For example

```
define user ask about self-harm
  "What are ways to hurt myself?"

define refuse to respond about self-harm
  "I am unable to help, sorry"

define flow self-harm
  user ask about self-harm
  bot refuse to respond about self-harm
```

In this Colang script, three blocks are defined: the user message blocks ```define user```, the bot message blocks ```define bot``` and the flow blocks ```define flow```. The user and bot message block defined by ```define ...``` is a structured representation of a message and is known as a canonical form. This is followed by utterances which are examples of messages that would fit into the defined canonical form. For example, "What are the ways to hurt myself?". The canonical form and the associated flows which describe the guardrails can then be determined based on semantic similarity of utterances.

The placement of rails on the input to or output from the generative model is also declarative: 

```
{config.yml}
rails:  
  output:
    flows:
      - self harm
  input:
    flows:
      - ....
```

#### Extending flows with custom logic for RAG applications

Flows can also be extended with programmable logic to build other types of rails such as Retrieval Rails and Execution Rails for a RAG application.

```
{config.yml}
define flow answer report question
  user ...
  $answer = execute rag()
  bot $answer
```

```
{config.py}
async def rag(context: dict, llm: BaseLLM, kb: KnowledgeBase) -> ActionResult:
     
    // e.g. fact checking, hallucination checking and source attribution

    return ActionResult(return_value=answer, context_updates=context_updates)
```

#### Using the WatsonxLLM LangChain Integration to integrate with watsonx.ai

Apply the config for LangChain's WatsonxLLM Integration:

```
{config.yml}
models:
 - type: main
   engine: watsonxllm
   model: <model>
   parameters:
      model_id: <model>
      project_id: <project_id>
      params:
        MAX_NEW_TOKENS: 200
        DECODING_METHOD: "sample"
        TEMPERATURE: 1.5
        TOP_K: 50
        TOP_P: 1
```

For a complete code example refer to: https://github.com/jamesdhope/nemo-guardrails-watsonx/blob/master/notebook.ipynb

Further Reading:

[1] LangChain Integrations: https://python.langchain.com/docs/integrations/llms/
[2] NeMo Guardrails Github: https://github.com/NVIDIA/NeMo-Guardrails
